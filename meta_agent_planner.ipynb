{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqdF9ir2DcNy",
        "outputId": "cb6a3da3-5f9d-42c5-c8d9-ddc2b9a45df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m378.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.5/891.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# install\n",
        "!pip install -qU langgraph langsmith langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mMbscmreDglB"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from typing import Optional, List, Annotated, Tuple\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from dataclasses import dataclass\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "emT6qYqH7zog"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvalResult:\n",
        "    passed: bool\n",
        "    details: str\n",
        "\n",
        "@dataclass\n",
        "class HLAState():\n",
        "    lla_code: str\n",
        "    lla_graph: Annotated[dict, \"json describing the graph nodes and edges\"]\n",
        "    task: str\n",
        "    eval_results: List[EvalResult]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ac7jwuG2xr6p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('HACKATHON_ANTHROPIC_API_KEY')\n",
        "\n",
        "\n",
        "NUM_TRIES = 3\n",
        "\n",
        "FORMAT =\"\"\"\n",
        "{\n",
        "    \"nodes\": [\n",
        "        {\n",
        "            \"name\": str,\n",
        "            \"description\": str,\n",
        "            \"input_names\": [str],\n",
        "            \"output_names\": [str]\n",
        "        }\n",
        "    ],\n",
        "    \"edges\": [\n",
        "        {\n",
        "            \"source_node\": str,\n",
        "            \"destination_node\": str\n",
        "        }\n",
        "    ],\n",
        "    \"cond_edges\": [\n",
        "        {\n",
        "            \"source_node\": str,\n",
        "            \"destinations\": [str]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n",
        "NEW_PLAN_PROMPT_TEMPLATE = PromptTemplate.from_template(\n",
        "\"\"\"In LangGraph, nodes are typically python functions where the first positional argument is the state.\n",
        "The START Node is a special node that represents the node sends user input to the graph. The main purpose for referencing this node is to determine which nodes should be called first.\n",
        "The END Node is a special node that represents a terminal node. This node is referenced when you want to denote which edges have no actions after they are done.\n",
        "\n",
        "Edges define how the logic is routed and how the graph decides to stop. This is a big part of how your agents work and how different nodes communicate with each other. There are a few key types of edges:\n",
        "- Normal Edges: Go directly from one node to the next.\n",
        "- Conditional Edges: Call a function to determine which node(s) to go to next.\n",
        "- Entry Point: Which node to call first when user input arrives.\n",
        "\n",
        "Describe the LangGraph nodes and edges you would use to accomplishes this task:\n",
        "{task}\n",
        "\n",
        "Give your response as JSON in the following format, don't include an explanation or anything other than JSON:\n",
        "{format}\n",
        "\"\"\"\n",
        ")\n",
        "REVISION_PROMPT_TEMPLATE = PromptTemplate.from_template(\n",
        "\"\"\"In LangGraph, nodes are typically python functions where the first positional argument is the state.\n",
        "The START Node is a special node that represents the node sends user input to the graph. The main purpose for referencing this node is to determine which nodes should be called first.\n",
        "The END Node is a special node that represents a terminal node. This node is referenced when you want to denote which edges have no actions after they are done.\n",
        "\n",
        "Edges define how the logic is routed and how the graph decides to stop. This is a big part of how your agents work and how different nodes communicate with each other. There are a few key types of edges:\n",
        "- Normal Edges: Go directly from one node to the next.\n",
        "- Conditional Edges: Call a function to determine which node(s) to go to next.\n",
        "- Entry Point: Which node to call first when user input arrives.\n",
        "\n",
        "Describe the LangGraph nodes and edges you would use to accomplishes this task:\n",
        "{task}\n",
        "\n",
        "A previous iteration attempted this, and output this graph:\n",
        "{graph}\n",
        "\n",
        "But, when we evaluated the result this is what we found:\n",
        "{eval_result}\n",
        "\n",
        "Try again, fixing the previous attempt. Respond with JSON in the following format, don't include an explanation or anything other than JSON:\n",
        "{format}\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2l-s9GcmqMfa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def planner(state: HLAState) -> HLAState:\n",
        "    assert state.task\n",
        "\n",
        "    llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "    if len(state.eval_results) == 0:\n",
        "        chain = NEW_PLAN_PROMPT_TEMPLATE | llm\n",
        "        response = chain.invoke({\"task\": state.task, \"format\": FORMAT})\n",
        "        # TODO: handle invalid json\n",
        "        state.lla_graph = json.loads(response.content)\n",
        "        return state\n",
        "    else:\n",
        "        chain = REVISION_PROMPT_TEMPLATE | llm\n",
        "        response = chain.invoke({\"task\": state.task, \"format\": FORMAT, \"graph\": state.lla_graph, \"eval_result\": state.eval_results[-1].details})\n",
        "        # TODO: handle invalid json\n",
        "        state.lla_graph = json.loads(response.content)\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jSjmuZ9Z-0EP"
      },
      "outputs": [],
      "source": [
        "def check_start_again(state: HLAState) -> str:\n",
        "    if len(state.eval_results) > NUM_TRIES:\n",
        "        return \"__end__\"\n",
        "    result = state.eval_results[-1]\n",
        "    if result.passed:\n",
        "        return \"__end__\"\n",
        "    return \"planner\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zd_O6JUgCiDM"
      },
      "outputs": [],
      "source": [
        "# test script\n",
        "\n",
        "def mock_evaluator(state: HLAState, does_pass: bool) -> HLAState:\n",
        "    result = EvalResult(does_pass, \"cond_edges should have >1 destinations\")\n",
        "    state.eval_results.append(result)\n",
        "    return state\n",
        "\n",
        "task = \"Tell me about the weather\"\n",
        "state = HLAState(\"\", [], task, [])\n",
        "state = planner(state)\n",
        "assert state.lla_code == \"\"\n",
        "assert state.lla_graph != \"\"\n",
        "assert state.task == task\n",
        "assert len(state.eval_results) == 0\n",
        "\n",
        "state = mock_evaluator(state, False)\n",
        "assert state.lla_graph != \"\"\n",
        "assert state.task == task\n",
        "assert len(state.eval_results) == 1\n",
        "assert not state.eval_results[-1].passed\n",
        "\n",
        "next_node = check_start_again(state)\n",
        "assert next_node == \"planner\"\n",
        "\n",
        "old_graph = state.lla_graph\n",
        "state = planner(state)\n",
        "assert state.lla_graph != \"\"\n",
        "assert state.lla_graph != old_graph\n",
        "assert state.task == task\n",
        "assert len(state.eval_results) == 1\n",
        "\n",
        "state = mock_evaluator(state, True)\n",
        "assert state.lla_graph != \"\"\n",
        "assert state.task == task\n",
        "assert len(state.eval_results) == 2\n",
        "assert state.eval_results[-1].passed\n",
        "\n",
        "next_node = check_start_again(state)\n",
        "assert next_node == \"__end__\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
